# AI Case Analysis

Leverage AI to analyze whistleblowing reports while maintaining strict data privacy and security.

## Overview

Disclosurely's AI Case Analysis uses advanced language models to help you:
- Identify key issues and patterns
- Assess severity and risk levels
- Generate investigation recommendations
- Draft communication responses
- Detect related cases

**Privacy First**: All AI processing includes automatic PII redaction and data anonymization.

## Features

### Automated Case Summarization
- Extract key facts from lengthy reports
- Identify involved parties (redacted)
- Highlight critical dates and events
- Categorize by issue type (harassment, fraud, safety, etc.)

### Risk Assessment
AI analyzes reports to determine:
- **Severity Score** (1-10)
- **Urgency Level** (Immediate, High, Medium, Low)
- **Potential Impact** (Legal, Financial, Reputational)
- **Recommended Actions**

### Pattern Detection
Identify trends across multiple reports:
- Recurring issues or behaviors
- Common departments or locations
- Similar complaint types
- Temporal patterns (spikes in specific periods)

### Investigation Assistance
Get AI-powered suggestions for:
- Key questions to ask
- Documents to request
- People to interview
- Evidence to gather

## How It Works

### 1. PII Redaction
Before AI analysis:
- Names, emails, phone numbers automatically redacted
- Replaced with consistent placeholders (e.g., `[PERSON_1]`)
- Addresses and identifying details masked
- Financial information protected

### 2. AI Processing
- Report sent to secure AI gateway
- Analysis performed on redacted text
- No data stored by AI provider (zero retention)
- Results returned encrypted

### 3. Case Insights
AI generates:
- Executive summary
- Key findings
- Risk assessment
- Recommended actions
- Related cases (if any)

## Privacy & Security

### Data Protection
- **No PII sent to AI** - All personal information redacted first
- **Zero data retention** - AI providers store nothing
- **Encrypted transit** - All data encrypted in motion
- **Audit trail** - Every AI request logged

### Supported Models
We support multiple AI providers for flexibility:
- OpenAI GPT-4
- Anthropic Claude
- Azure OpenAI
- AWS Bedrock
- Self-hosted models (Llama, Mistral)

### Compliance
AI features are designed to comply with:
- GDPR (data minimization)
- EU AI Act requirements
- SOC 2 data handling standards
- ISO 27001 security controls

## Usage

### Analyzing a Report
1. Open any report in your dashboard
2. Click **AI Case Helper** in the sidebar
3. Select the report to analyze
4. Click **Preview PII Redaction** (review what will be sent)
5. Click **Start Analysis**
6. View results in conversational format

### Asking Follow-Up Questions
After initial analysis, you can chat with the AI:
- "What are the main legal risks here?"
- "Who should we interview first?"
- "Is this related to case #123?"
- "Draft a response to the reporter"

### Saving Analyses
- All analyses are saved to the case file
- Access previous analyses via **Saved Analyses** dropdown
- Delete sensitive analyses if needed

## Best Practices

### When to Use AI
✅ **Good use cases:**
- Initial case triage
- Identifying investigation steps
- Drafting communications
- Finding patterns across cases

❌ **Avoid using AI for:**
- Final legal decisions (consult counsel)
- Disciplinary actions (requires human judgment)
- Sensitive political matters
- Cases requiring nuanced cultural understanding

### Reviewing AI Output
Always review AI suggestions critically:
- Verify facts against original report
- Consider organizational context
- Consult legal/HR for serious cases
- Use as a starting point, not final answer

## FAQ

**Is my data sent to OpenAI/Anthropic?**  
Only redacted, anonymized text is sent. No personal information leaves your environment.

**Can I use my own AI models?**  
Yes! Enterprise plans support self-hosted models for complete data isolation.

**How accurate is the AI?**  
AI suggestions should be reviewed by humans. Accuracy varies based on report quality and complexity.

**What if AI makes a mistake?**  
Always verify AI output. We're not liable for AI-generated content - it's advisory only.

**Can I disable AI features?**  
Yes. Navigate to Settings > AI to disable analysis for your organization.

